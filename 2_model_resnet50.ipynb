{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pneumonia Detection â€“ ResNet50 Transfer Learning\n",
        "\n",
        "This notebook builds and trains a pneumonia detector using ResNet50 as a frozen feature extractor with a custom classification head. It augments training data, trains for 10 epochs, evaluates on the test set, saves figures to `results/`, and exports the trained model to `models/resnet50_final.h5`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "plt.rcParams[\"figure.dpi\"] = 120\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths and hyperparameters\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "DATA_DIR = PROJECT_ROOT / \"data\" / \"chest_xray\"\n",
        "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
        "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
        "for d in [RESULTS_DIR, MODELS_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(f\"Data dir: {DATA_DIR}\")\n",
        "print(f\"Results dir: {RESULTS_DIR}\")\n",
        "print(f\"Models dir: {MODELS_DIR}\")\n",
        "\n",
        "if not DATA_DIR.exists():\n",
        "    raise FileNotFoundError(\"Dataset not found at data/chest_xray. Place it before running.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data generators with augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "val_test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "train_dir = DATA_DIR / \"train\"\n",
        "val_dir = DATA_DIR / \"val\"\n",
        "test_dir = DATA_DIR / \"test\"\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=True,\n",
        "    seed=SEED,\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=False,\n",
        "    seed=SEED,\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=False,\n",
        "    seed=SEED,\n",
        ")\n",
        "\n",
        "print(\"Class indices:\", train_generator.class_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(input_shape=(224, 224, 3)):\n",
        "    base_model = ResNet50(\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        input_tensor=Input(shape=input_shape),\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation=\"relu\")(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\", tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\")],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_model(input_shape=IMG_SIZE + (3,))\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_path = MODELS_DIR / \"resnet50_best.h5\"\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        filepath=checkpoint_path,\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        save_best_only=True,\n",
        "        verbose=1,\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=3,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1,\n",
        "    ),\n",
        "]\n",
        "\n",
        "steps_per_epoch = train_generator.samples // BATCH_SIZE\n",
        "validation_steps = val_generator.samples // BATCH_SIZE\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "axes[0].plot(hist_df[\"loss\"], label=\"train\")\n",
        "axes[0].plot(hist_df[\"val_loss\"], label=\"val\")\n",
        "axes[0].set_title(\"Loss\")\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(hist_df[\"accuracy\"], label=\"train\")\n",
        "axes[1].plot(hist_df[\"val_accuracy\"], label=\"val\")\n",
        "axes[1].set_title(\"Accuracy\")\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "train_plot_path = RESULTS_DIR / \"resnet50_training_curves.png\"\n",
        "plt.savefig(train_plot_path, dpi=300)\n",
        "print(f\"Saved training curves to {train_plot_path}\")\n",
        "plt.show()\n",
        "\n",
        "hist_df.to_csv(RESULTS_DIR / \"resnet50_history.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "print(\"Evaluating on test set...\")\n",
        "test_steps = test_generator.samples // BATCH_SIZE\n",
        "pred_probs = model.predict(test_generator, steps=test_steps + 1, verbose=1).ravel()\n",
        "pred_labels = (pred_probs >= 0.5).astype(int)\n",
        "true_labels = test_generator.classes[: len(pred_labels)]\n",
        "\n",
        "acc = accuracy_score(true_labels, pred_labels)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average=\"binary\", zero_division=0)\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "metrics = {\n",
        "    \"accuracy\": acc,\n",
        "    \"precision\": precision,\n",
        "    \"recall\": recall,\n",
        "    \"f1_score\": f1,\n",
        "}\n",
        "print(\"Metrics:\", metrics)\n",
        "\n",
        "metrics_df = pd.DataFrame([metrics])\n",
        "metrics_csv = RESULTS_DIR / \"resnet50_metrics.csv\"\n",
        "metrics_df.to_csv(metrics_csv, index=False)\n",
        "print(f\"Saved metrics to {metrics_csv}\")\n",
        "\n",
        "# Confusion matrix plot\n",
        "fig, ax = plt.subplots(figsize=(4, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=ax)\n",
        "ax.set_xlabel(\"Predicted\")\n",
        "ax.set_ylabel(\"True\")\n",
        "ax.set_title(\"ResNet50 Confusion Matrix\")\n",
        "cm_path = RESULTS_DIR / \"resnet50_confusion_matrix.png\"\n",
        "plt.tight_layout()\n",
        "plt.savefig(cm_path, dpi=300)\n",
        "print(f\"Saved confusion matrix to {cm_path}\")\n",
        "plt.show()\n",
        "\n",
        "# Save final model\n",
        "final_model_path = MODELS_DIR / \"resnet50_final.h5\"\n",
        "model.save(final_model_path)\n",
        "print(f\"Saved model to {final_model_path}\")\n",
        "\n",
        "# Persist metrics JSON for comparison notebook\n",
        "with open(RESULTS_DIR / \"resnet50_metrics.json\", \"w\") as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "print(\"Stored metrics JSON for comparison.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
